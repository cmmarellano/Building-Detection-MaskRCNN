{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11518658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574f6445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Aug  9 20:02:23 2020\n",
    "@author: MUSTAFAAKTAS\n",
    "\n",
    "Modified Aug  2022\n",
    "@author: cmmarellano\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import geopandas as gpd \n",
    "import geoio\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c870bb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"C:\\\\Users\\\\carellano.LEGION5PRO-O3OB\\\\Documents\\\\IP AppDev\\\\Final_Project\\\\SpaceNet\\\\\")\n",
    "dataset_dir = os.path.abspath(\"C:\\\\Users\\\\carellano.LEGION5PRO-O3OB\\\\Documents\\\\IP AppDev\\\\Final_Project\\\\SpaceNet\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32ba37b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e54655c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5459597b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carellano.LEGION5PRO-O3OB\\Documents\\IP AppDev\\Final_Project\\SpaceNet\\mask_rcnn_spacenet_0151\\mask_rcnn_spacenet_0151.h5\n",
      "- - model located\n",
      "Specify COCO_MODEL_PATH !\n"
     ]
    }
   ],
   "source": [
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"C:\\\\Users\\\\carellano.LEGION5PRO-O3OB\\\\Documents\\\\IP AppDev\\\\Final_Project\\\\SpaceNet\\\\mask_rcnn_spacenet_0151\\\\mask_rcnn_spacenet_0151.h5\")\n",
    "print(COCO_MODEL_PATH)\n",
    "print('- - model located')\n",
    "\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "    print('Specify COCO_MODEL_PATH !')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44acd8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data locations for images and annotations\n",
    "images_dir = os.path.join(dataset_dir, \"PS-RGB_select_png\\\\\")\n",
    "annotations_dir = os.path.join(dataset_dir, \"building_labels_select_geojson\\\\\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57096fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet50\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        350\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  640\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  640\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [640 640   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               250\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           SpaceNet\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.25, 1, 4]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                500\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           10\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class SpaceNetConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"SpaceNet\"\n",
    "    BACKBONE = \"resnet50\"\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # background + 1 building\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 640\n",
    "    IMAGE_MAX_DIM = 640\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "    RPN_ANCHOR_RATIOS = [0.25, 1, 4]\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 5  #10    #32\n",
    "\n",
    "    USE_MINI_MASK = True\n",
    "    \n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 50 #500\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 10 #50\n",
    "    \n",
    "    MAX_GT_INSTANCES=250\n",
    "    DETECTION_MAX_INSTANCES=350\n",
    "    \n",
    "config = SpaceNetConfig()\n",
    "config.display()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "273ef3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n",
    "\n",
    "def fill_between(polygon):\n",
    "    \"\"\"\n",
    "    Returns: a bool array\n",
    "    \"\"\"\n",
    "    img = Image.new('1', (650, 650), False)\n",
    "    ImageDraw.Draw(img).polygon(polygon, outline=True, fill=True)\n",
    "    mask = np.array(img)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "865bfcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SpaceNetDataset(utils.Dataset):\n",
    "    \"\"\"Generates the shapes synthetic dataset. The dataset consists of simple\n",
    "    shapes (triangles, squares, circles) placed randomly on a blank surface.\n",
    "    The images are generated on the fly. No file access required.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    def load_dataset(self, dataset_dir=dataset_dir, start=0, end=10):   # 1-400\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.start=start\n",
    "        self.end=end\n",
    "        \n",
    "        # Add classes\n",
    "        self.add_class(\"SpaceNetDataset\", 1, \"building\")\n",
    "\n",
    "        # define data locations for images and annotations\n",
    "        images_dir = os.path.join(dataset_dir, \"PS-RGB_select_png\\\\\")\n",
    "        annotations_dir = os.path.join(dataset_dir, \"building_labels_select_geojson\\\\\")\n",
    "        \n",
    "        # Iterate through all files in the folder to \n",
    "        #add class, images and annotaions\n",
    "        \n",
    "#         image_id_list =[]\n",
    "#         counters = 1\n",
    "        for filename in os.listdir(images_dir)[start:end]:\n",
    "#             print(counters)\n",
    "#             print(filename)        \n",
    "            id_base  = os.path.basename(filename)\n",
    "            finder= 'PS-RGB_img'\n",
    "            id_start = filename.find(finder)+ len(finder)\n",
    "            id_end = filename.find(\".png\")\n",
    "            image_id = filename[id_start:id_end]\n",
    "            image_dir = os.path.join(images_dir,str(filename))\n",
    "            ann_path  = os.path.join(annotations_dir,\"label_img\"+str(image_id)+\".geojson\")  \n",
    "#             print(\"image id : \",image_id)\n",
    "#             print(\"image dir : \",image_dir)\n",
    "#             print(\"ann path : \",ann_path)\n",
    "            \n",
    "            self.add_image('SpaceNetDataset', image_id=image_id, path=image_dir, annotation=ann_path)\n",
    "#             counters = counters+1\n",
    "#             image_id_list.append(image_id)\n",
    "#         print(\"\\nimage ids loaded: \", image_id_list)\n",
    "        \n",
    "#         self.image_id_list = image_id_list\n",
    "    \n",
    "        \n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Generate an image from the specs of the given image ID.\n",
    "            Typically this function loads the image from a file, but\n",
    "            in this case it generates the image on the fly from the\n",
    "            specs in image_info.\n",
    "        \"\"\"\n",
    "#         self.load_dataset()\n",
    "#         cont_id = image_id\n",
    "#         image_id = self.image_id_list[cont_id]\n",
    "        \n",
    "        # define data locations for images and annotations\n",
    "        images_dir = os.path.join(dataset_dir, \"PS-RGB_select_png\\\\\")\n",
    "        annotations_dir = os.path.join(dataset_dir, \"building_labels_select_geojson\\\\\")\n",
    "\n",
    "        # Iterate through all files in the folder to \n",
    "        #add class, images and annotaions   \n",
    "\n",
    "        image_dir = os.path.join(dataset_dir+\"\\\\PS-RGB_select_png\\\\PS-RGB_img\"+str(image_id)+\".png\")\n",
    "        im = Image.open(image_dir)\n",
    "        return np.asarray(im)\n",
    "\n",
    "\n",
    "        \n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"shapes\":\n",
    "            return info[\"shapes\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        masks = np.zeros((650,650))\n",
    "        bldgmask_path = \"C:\\\\Users\\\\carellano.LEGION5PRO-O3OB\\\\Documents\\\\IP AppDev\\\\Final_Project\\\\SpaceNet\\\\mask_for_training\\\\\"\n",
    "        ResimPATH = bldgmask_path+\"mask_img\"+str(image_id)+'.png'\n",
    "        RGBTIFResmi = geoio.GeoImage(ResimPATH)\n",
    "        \n",
    "        with open(dataset_dir+\"\\\\building_labels_select_geojson\\\\label_img\"+str(image_id)+\".geojson\") as f:\n",
    "            data = json.load(f)\n",
    "            allBuildings = data['features']\n",
    "              \n",
    "            for building in allBuildings:   \n",
    "                veri = building['geometry']['coordinates'][0]\n",
    "                \n",
    "                tip = str(building['geometry']['type'])\n",
    "                coordinates = list() \n",
    "                if tip == ('Point'):\n",
    "                    continue\n",
    "                    \n",
    "                elif tip == ('MultiPolygon'):\n",
    "                    \n",
    "                    if isinstance(veri,float): continue\n",
    "                        \n",
    "                    kucukBinalar = (building['geometry']['coordinates'])\n",
    "                    for b in range(len(kucukBinalar)):  \n",
    "                        veri = kucukBinalar[b][0]\n",
    "                        for i in veri:\n",
    "                            xPixel, yPixel = RGBTIFResmi.proj_to_raster(i[0], i[1])\n",
    "                            xPixel = 649 if xPixel > 649 else xPixel\n",
    "                            yPixel = 649 if yPixel > 649 else yPixel\n",
    "                            coordinates.append((xPixel,yPixel)) \n",
    "                else:\n",
    "                    if isinstance(veri,float): continue\n",
    "    \n",
    "                    for i in veri:\n",
    "                        xPixel, yPixel = RGBTIFResmi.proj_to_raster(i[0], i[1])\n",
    "                        xPixel = 649 if xPixel > 649 else xPixel\n",
    "                        yPixel = 649 if yPixel > 649 else yPixel\n",
    "                        coordinates.append((xPixel,yPixel))\n",
    "\n",
    "                maske = fill_between(coordinates)\n",
    "                masks = np.dstack((masks,maske))\n",
    "\n",
    "                \n",
    "        if masks.shape != (650,650):\n",
    "            masks = masks[:,:,1:]\n",
    "            class_ids = np.asarray([1]*masks.shape[2])\n",
    "        else:\n",
    "            class_ids=np.ones((1))\n",
    "            masks = masks.reshape((650,650,1))\n",
    "        return masks.astype(np.bool), class_ids.astype(np.int32)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "525c9afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = SpaceNetDataset()\n",
    "dataset_train.load_dataset(dataset_dir,0,12) \n",
    "dataset_train.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a61d17b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 12\n",
      "Classes: ['BG', 'building']\n"
     ]
    }
   ],
   "source": [
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset_train.image_ids), dataset_train.class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92348be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataset\n",
    "dataset_val = SpaceNetDataset()\n",
    "dataset_val.load_dataset(dataset_dir,12,16)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7744851b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 4\n",
      "Classes: ['BG', 'building']\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset_val.image_ids), dataset_val.class_names))\n",
    "print(dataset_val.image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c6dbc28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: C:\\Users\\carellano.LEGION5PRO-O3OB\\Documents\\IP AppDev\\Final_Project\\SpaceNet\\logs\\spacenet20220818T1855\\mask_rcnn_spacenet_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "anchors                (ConstLayer)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carellano.LEGION5PRO-O3OB\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create model in training mode  -> SpaceNet config\u001b[39;00m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m modellib\u001b[38;5;241m.\u001b[39mMaskRCNN(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m, config\u001b[38;5;241m=\u001b[39mconfig, model_dir\u001b[38;5;241m=\u001b[39mMODEL_DIR)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\py39_tf\\lib\\site-packages\\mask_rcnn-2.1-py3.9.egg\\mrcnn\\model.py:2357\u001b[0m, in \u001b[0;36mMaskRCNN.train\u001b[1;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2355\u001b[0m     workers \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mcpu_count()\n\u001b[1;32m-> 2357\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2361\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTEPS_PER_EPOCH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVALIDATION_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2367\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch, epochs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training_v1.py:776\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    775\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[1;32m--> 776\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training_generator_v1.py:570\u001b[0m, in \u001b[0;36mGeneratorOrSequenceTrainingLoop.fit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    567\u001b[0m model\u001b[38;5;241m.\u001b[39m_validate_or_infer_batch_size(batch_size, steps_per_epoch, x)\n\u001b[0;32m    568\u001b[0m training_utils_v1\u001b[38;5;241m.\u001b[39mcheck_generator_arguments(\n\u001b[0;32m    569\u001b[0m     y, sample_weight, validation_split\u001b[38;5;241m=\u001b[39mvalidation_split)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msteps_per_epoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training_generator_v1.py:212\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m step \u001b[38;5;241m<\u001b[39m target_steps:\n\u001b[1;32m--> 212\u001b[0m   batch_data \u001b[38;5;241m=\u001b[39m \u001b[43m_get_next_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m batch_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_dataset:\n\u001b[0;32m    215\u001b[0m       \u001b[38;5;66;03m# The dataset passed by the user ran out of batches.\u001b[39;00m\n\u001b[0;32m    216\u001b[0m       \u001b[38;5;66;03m# Now we know the cardinality of the dataset.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m       \u001b[38;5;66;03m# If steps_per_epoch was specified, then running out of data is\u001b[39;00m\n\u001b[0;32m    218\u001b[0m       \u001b[38;5;66;03m# unexpected, so we stop training and inform the user.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training_generator_v1.py:346\u001b[0m, in \u001b[0;36m_get_next_batch\u001b[1;34m(generator)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 346\u001b[0m   generator_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mStopIteration\u001b[39;00m, tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mOutOfRangeError):\n\u001b[0;32m    348\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\data_utils.py:514\u001b[0m, in \u001b[0;36miter_sequence_infinite\u001b[1;34m(seq)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;124;03m\"\"\"Iterates indefinitely over a Sequence.\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m  Batches of data from the `Sequence`.\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 514\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m seq:\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\data_utils.py:500\u001b[0m, in \u001b[0;36mSequence.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    499\u001b[0m   \u001b[38;5;124;03m\"\"\"Create a generator that iterate over the Sequence.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 500\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mself\u001b[39m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))):\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\data_utils.py:500\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    499\u001b[0m   \u001b[38;5;124;03m\"\"\"Create a generator that iterate over the Sequence.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 500\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))):\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\py39_tf\\lib\\site-packages\\mask_rcnn-2.1-py3.9.egg\\mrcnn\\model.py:1719\u001b[0m, in \u001b[0;36mDataGenerator.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m   1716\u001b[0m \u001b[38;5;66;03m# Get GT bounding boxes and masks for image.\u001b[39;00m\n\u001b[0;32m   1717\u001b[0m image_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_ids[image_index]\n\u001b[0;32m   1718\u001b[0m image, image_meta, gt_class_ids, gt_boxes, gt_masks \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m-> 1719\u001b[0m     \u001b[43mload_image_gt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1720\u001b[0m \u001b[43m                  \u001b[49m\u001b[43maugmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugmentation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;66;03m# Skip images that have no instances. This can happen in cases\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m \u001b[38;5;66;03m# where we train on a subset of classes and the image doesn't\u001b[39;00m\n\u001b[0;32m   1724\u001b[0m \u001b[38;5;66;03m# have any of the classes we care about.\u001b[39;00m\n\u001b[0;32m   1725\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(gt_class_ids \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\py39_tf\\lib\\site-packages\\mask_rcnn-2.1-py3.9.egg\\mrcnn\\model.py:1234\u001b[0m, in \u001b[0;36mload_image_gt\u001b[1;34m(dataset, config, image_id, augmentation)\u001b[0m\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;66;03m# Load image and mask\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m image \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mload_image(image_id)\n\u001b[1;32m-> 1234\u001b[0m mask, class_ids \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1235\u001b[0m original_shape \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1236\u001b[0m image, window, scale, padding, crop \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mresize_image(\n\u001b[0;32m   1237\u001b[0m     image,\n\u001b[0;32m   1238\u001b[0m     min_dim\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mIMAGE_MIN_DIM,\n\u001b[0;32m   1239\u001b[0m     min_scale\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mIMAGE_MIN_SCALE,\n\u001b[0;32m   1240\u001b[0m     max_dim\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mIMAGE_MAX_DIM,\n\u001b[0;32m   1241\u001b[0m     mode\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mIMAGE_RESIZE_MODE)\n",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36mSpaceNetDataset.load_mask\u001b[1;34m(self, image_id)\u001b[0m\n\u001b[0;32m    123\u001b[0m                 yPixel \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m649\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m yPixel \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m649\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m yPixel\n\u001b[0;32m    124\u001b[0m                 coordinates\u001b[38;5;241m.\u001b[39mappend((xPixel,yPixel))\n\u001b[1;32m--> 126\u001b[0m         maske \u001b[38;5;241m=\u001b[39m \u001b[43mfill_between\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoordinates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m         masks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdstack((masks,maske))\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m masks\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m650\u001b[39m,\u001b[38;5;241m650\u001b[39m):\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mfill_between\u001b[1;34m(polygon)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfill_between\u001b[39m(polygon):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    Returns: a bool array\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m650\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m650\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     ImageDraw\u001b[38;5;241m.\u001b[39mDraw(img)\u001b[38;5;241m.\u001b[39mpolygon(polygon, outline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m     mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\py39_tf\\lib\\site-packages\\PIL\\Image.py:2806\u001b[0m, in \u001b[0;36mnew\u001b[1;34m(mode, size, color)\u001b[0m\n\u001b[0;32m   2804\u001b[0m     im\u001b[38;5;241m.\u001b[39mpalette \u001b[38;5;241m=\u001b[39m ImagePalette\u001b[38;5;241m.\u001b[39mImagePalette()\n\u001b[0;32m   2805\u001b[0m     color \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mgetcolor(color)\n\u001b[1;32m-> 2806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m im\u001b[38;5;241m.\u001b[39m_new(\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#####  MODEL FOR TRAINING  ##############\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(action='ignore', category=DeprecationWarning, message='`np.bool` is a deprecated alias')\n",
    "\n",
    "\n",
    "\n",
    "# Create model in training mode  -> SpaceNet config\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)\n",
    "\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=200, \n",
    "            layers='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e58ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load and display random samples\n",
    "# print(dataset_train.image_ids)\n",
    "# image_ids = np.random.choice(dataset_train.image_ids,2)\n",
    "# print(image_ids)\n",
    "# for image_id in range(len(image_ids)):\n",
    "#     print(image_id)\n",
    "#     image = dataset_train.load_image(image_id)\n",
    "#     mask, class_ids = dataset_train.load_mask(image_id)\n",
    "#     visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model in inference mode\n",
    "# model = modellib.MaskRCNN(mode=\"inference\", \n",
    "#                           config=inference_config,\n",
    "#                           model_dir=MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0103bff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(COCO_MODEL_PATH, by_name=True, exclude=[\n",
    "#             \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "#             \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ee538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_image, image_meta, gt_class_id, gt_bbox, gt_mask =modellib.load_image_gt(dataset_val, inference_config, image_id) #use_mini_mask=False'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f119b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log(\"original_image\", original_image)\n",
    "# log(\"image_meta\", image_meta)\n",
    "# log(\"gt_class_id\", gt_class_id)\n",
    "# log(\"gt_bbox\", gt_bbox)\n",
    "# log(\"gt_mask\", gt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6c356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train(dataset_train, dataset_val, \n",
    "#             learning_rate=config.LEARNING_RATE, \n",
    "# #             epochs=200, \n",
    "#             layers='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180aaff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####   DETECTION     ####\n",
    "# class InferenceConfig(SpaceNetConfig):\n",
    "#     GPU_COUNT = 1\n",
    "#     IMAGES_PER_GPU = 1\n",
    "\n",
    "# inference_config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d8c268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab51bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "#                             dataset_train.class_names, figsize=(8, 8))\n",
    "\n",
    "# results = model.detect([original_image], verbose=1)\n",
    "# r = results[0]\n",
    "# visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "#                             dataset_val.class_names, r['scores'], ax=get_ax())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c21beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Compute VOC-Style mAP @ IoU=0.5\n",
    "# # Running on 10 images. Increase for better accuracy.\n",
    "# image_ids = np.random.choice(dataset_val.image_ids, 6)\n",
    "# APs = []\n",
    "# for image_id in image_ids:\n",
    "#     # Load image and ground truth data\n",
    "#     image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "#         modellib.load_image_gt(dataset_val, inference_config,\n",
    "#                                image_id) #, use_mini_mask=False\n",
    "#     molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "#     # Run object detection\n",
    "#     results = model.detect([image], verbose=0)\n",
    "#     r = results[0]\n",
    "#     # Compute AP\n",
    "#     AP, precisions, recalls, overlaps =\\\n",
    "#         utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "#                          r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "#     APs.append(AP)\n",
    "    \n",
    "# print(\"mAP: \", np.mean(APs))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39 (TF2.9.1)",
   "language": "python",
   "name": "py39_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
