{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11518658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574f6445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Aug  9 20:02:23 2020\n",
    "@author: MUSTAFAAKTAS\n",
    "\n",
    "Modified Jul Aug 2022\n",
    "@author: cmmarellano\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import geopandas as gpd \n",
    "import geoio\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 3,
   "id": "32ba37b4",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 2,
   "id": "c870bb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"C:\\\\Users\\\\carellano.LEGION5PRO-O3OB\\\\Documents\\\\IP AppDev\\\\Final_Project\\\\SpaceNet\\\\\")\n",
    "dataset_dir = os.path.abspath(\"C:\\\\Users\\\\carellano.LEGION5PRO-O3OB\\\\Documents\\\\IP AppDev\\\\Final_Project\\\\SpaceNet\\\\\")\n",
    "train_dir =os.path.abspath(\"C:\\\\Users\\\\carellano.LEGION5PRO-O3OB\\\\Documents\\\\IP AppDev\\\\Final_Project\\\\SpaceNet\\\\train\")\n",
    "val_dir= os.path.abspath(\"C:\\\\Users\\\\carellano.LEGION5PRO-O3OB\\\\Documents\\\\IP AppDev\\\\Final_Project\\\\SpaceNet\\val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c696e960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\carellano.LEGION5PRO-O3OB\\\\Documents\\\\IP AppDev\\\\Final_Project\\\\SpaceNet\\\\train'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32ba37b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\py39_tf\\lib\\site-packages\\mrcnn\\model.py:2373: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if os.name is 'nt':\n",
      "C:\\ProgramData\\Miniconda3\\envs\\py39_tf\\lib\\site-packages\\mrcnn\\model.py:2373: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if os.name is 'nt':\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.engine' has no attribute 'Layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmrcnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmrcnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmrcnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmodellib\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmrcnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m visualize\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmrcnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m log\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\py39_tf\\lib\\site-packages\\mrcnn\\model.py:255\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    251\u001b[0m     clipped\u001b[38;5;241m.\u001b[39mset_shape((clipped\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clipped\n\u001b[1;32m--> 255\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mProposalLayer\u001b[39;00m(\u001b[43mKE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLayer\u001b[49m):\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;124;03m\"\"\"Receives anchor scores and selects a subset to pass as proposals\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124;03m    to the second stage. Filtering is done based on anchor scores and\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124;03m    non-max suppression to remove overlaps. It also applies bounding\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;124;03m        Proposals in normalized coordinates [batch, rois, (y1, x1, y2, x2)]\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, proposal_count, nms_threshold, config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.engine' has no attribute 'Layer'"
     ]
    }
   ],
>>>>>>> Stashed changes
   "source": [
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 2,
   "id": "c870bb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"C:\\\\Users\\\\carellano.LEGION5PRO-O3OB\\\\Documents\\\\IP AppDev\\\\Final_Project\\\\SpaceNet\\\\\")\n",
    "dataset_dir = os.path.abspath(\"C:\\\\Users\\\\carellano.LEGION5PRO-O3OB\\\\Documents\\\\IP AppDev\\\\Final_Project\\\\SpaceNet\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "e54655c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 5,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "5459597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Local path to trained weights file\n",
    "# COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"C:\\\\Users\\\\carellano.LEGION5PRO-O3OB\\\\Documents\\\\IP AppDev\\\\Final_Project\\\\SpaceNet\\\\mask_rcnn_spacenet_0151\\\\mask_rcnn_spacenet_0151.h5\")\n",
    "# print(COCO_MODEL_PATH)\n",
    "# print('- - model located')\n",
    "# # Download COCO trained weights from Releases if needed\n",
    "# if not os.path.exists(COCO_MODEL_PATH):\n",
    "#     utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "#     print('Specify COCO_MODEL_PATH !')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 6,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "44acd8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data locations for images and annotations\n",
<<<<<<< Updated upstream
    "images_dir = os.path.join(dataset_dir, \"PS-RGB_select_png\\\\\")\n",
=======
    "images_dir = os.path.join(dataset_dir, \"PS-RGB_selected_tif\\\\\")\n",
>>>>>>> Stashed changes
    "annotations_dir = os.path.join(dataset_dir, \"building_labels_select_geojson\\\\\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 7,
   "id": "57096fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet50\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        350\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  640\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  640\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [640 640   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               250\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           SpaceNet\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.25, 1, 4]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                5\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           1\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               2\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "id": "57096fea",
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "class SpaceNetConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"SpaceNet\"\n",
    "    BACKBONE = \"resnet50\"\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
<<<<<<< Updated upstream
=======
    "    # batch size =1!\n",
>>>>>>> Stashed changes
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1  #1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # background + 1 building\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 640\n",
    "    IMAGE_MAX_DIM = 640\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "    RPN_ANCHOR_RATIOS = [0.25, 1, 4]\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 1  #10    #32\n",
    "\n",
    "    USE_MINI_MASK = True\n",
    "    \n",
    "    # Use a small epoch since the data is simple\n",
<<<<<<< Updated upstream
    "    STEPS_PER_EPOCH = 5 #50  #500\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 2 #50\n",
    "    \n",
    "    MAX_GT_INSTANCES=250\n",
    "    DETECTION_MAX_INSTANCES=350\n",
=======
    "    STEPS_PER_EPOCH = 12 #500 #must be number of train samples//batch_size!\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 4 #50  #number of validation samples//batch_size\n",
    "    \n",
    "    MAX_GT_INSTANCES=50 #250\n",
    "    DETECTION_MAX_INSTANCES=50  #350\n",
>>>>>>> Stashed changes
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "config = SpaceNetConfig()\n",
    "config.display()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 8,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "67711dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n",
    "\n",
    "def fill_between(polygon):\n",
    "    \"\"\"\n",
    "    Returns: a bool array\n",
    "    \"\"\"\n",
    "    img = Image.new('1', (650, 650), False)\n",
    "    ImageDraw.Draw(img).polygon(polygon, outline=True, fill=True)\n",
    "    mask = np.array(img)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 9,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "865bfcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SpaceNetDataset(utils.Dataset):\n",
    "    \"\"\"Generates the shapes synthetic dataset. The dataset consists of simple\n",
    "    shapes (triangles, squares, circles) placed randomly on a blank surface.\n",
    "    The images are generated on the fly. No file access required.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
<<<<<<< Updated upstream
    "    def load_dataset(self, dataset_dir=dataset_dir, start=0, end=20):   # 1-400\n",
=======
    "    def load_dataset(self, dataset_dir=dataset_dir, start=1, end=400):   # 1-400\n",
>>>>>>> Stashed changes
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        \n",
<<<<<<< Updated upstream
    "        self.start=start\n",
    "        self.end=end\n",
=======
>>>>>>> Stashed changes
    "        \n",
    "        # Add classes\n",
    "        self.add_class(\"SpaceNetDataset\", 1, \"building\")\n",
    "\n",
    "        # define data locations for images and annotations\n",
    "        images_dir = os.path.join(dataset_dir, \"PS-RGB_select_png\\\\\")\n",
    "        annotations_dir = os.path.join(dataset_dir, \"building_labels_select_geojson\\\\\")\n",
    "        \n",
    "        # Iterate through all files in the folder to \n",
    "        #add class, images and annotaions\n",
    "        \n",
    "#         image_id_list =[]\n",
    "#         counters = 1\n",
    "        for filename in os.listdir(images_dir)[start:end]:\n",
    "#             print(counters)\n",
    "#             print(filename)        \n",
    "            id_base  = os.path.basename(filename)\n",
    "            finder= 'PS-RGB_img'\n",
    "            id_start = filename.find(finder)+ len(finder)\n",
<<<<<<< Updated upstream
    "            id_end = filename.find(\".png\")\n",
=======
    "            id_end = filename.find(\".tif\")\n",
>>>>>>> Stashed changes
    "            image_id = filename[id_start:id_end]\n",
    "            image_dir = os.path.join(images_dir,str(filename))\n",
    "            ann_path  = os.path.join(annotations_dir,\"label_img\"+str(image_id)+\".geojson\")  \n",
    "#             print(\"image id : \",image_id)\n",
    "#             print(\"image dir : \",image_dir)\n",
    "#             print(\"ann path : \",ann_path)\n",
    "            \n",
    "            self.add_image('SpaceNetDataset', image_id=image_id, path=image_dir, annotation=ann_path)\n",
    "#             counters = counters+1\n",
    "#             image_id_list.append(image_id)\n",
    "#         print(\"\\nimage ids loaded: \", image_id_list)\n",
    "        \n",
    "#         self.image_id_list = image_id_list\n",
    "    \n",
    "        \n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Generate an image from the specs of the given image ID.\n",
    "            Typically this function loads the image from a file, but\n",
    "            in this case it generates the image on the fly from the\n",
    "            specs in image_info.\n",
    "        \"\"\"\n",
<<<<<<< Updated upstream
    "#         self.load_dataset()\n",
    "#         cont_id = image_id\n",
    "#         image_id = self.image_id_list[cont_id]\n",
    "        \n",
    "        # define data locations for images and annotations\n",
    "        images_dir = os.path.join(dataset_dir, \"PS-RGB_select_png\\\\\")\n",
    "        annotations_dir = os.path.join(dataset_dir, \"building_labels_select_geojson\\\\\")\n",
    "\n",
    "        # Iterate through all files in the folder to \n",
    "        #add class, images and annotaions   \n",
=======
>>>>>>> Stashed changes
    "\n",
    "        image_dir = os.path.join(dataset_dir+\"\\\\PS-RGB_select_png\\\\PS-RGB_img\"+str(image_id)+\".png\")\n",
    "        im = Image.open(image_dir)\n",
    "        return np.asarray(im)\n",
    "\n",
    "\n",
    "        \n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"shapes\":\n",
    "            return info[\"shapes\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
<<<<<<< Updated upstream
=======
    "            \n",
>>>>>>> Stashed changes
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        masks = np.zeros((650,650))\n",
<<<<<<< Updated upstream
    "        bldgmask_path = \"C:\\\\Users\\\\carellano.LEGION5PRO-O3OB\\\\Documents\\\\IP AppDev\\\\Final_Project\\\\SpaceNet\\\\mask_for_training\\\\\"\n",
    "        ResimPATH = bldgmask_path+\"mask_img\"+str(image_id)+'.png'\n",
=======
    "#         bldgmask_path = \"C:\\\\Users\\\\carellano.LEGION5PRO-O3OB\\\\Documents\\\\IP AppDev\\\\Final_Project\\\\SpaceNet\\\\mask_for_training\\\\\"\n",
    "#         ResimPATH = bldgmask_path+\"mask_img\"+str(image_id)+'.png'\n",
    "        ResimPATH = os.path.join(dataset_dir+\"\\\\PS-RGB_select_png\\\\PS-RGB_img\"+str(image_id)+\".png\")\n",
>>>>>>> Stashed changes
    "        RGBTIFResmi = geoio.GeoImage(ResimPATH)\n",
    "        \n",
    "        with open(dataset_dir+\"\\\\building_labels_select_geojson\\\\label_img\"+str(image_id)+\".geojson\") as f:\n",
    "            data = json.load(f)\n",
    "            allBuildings = data['features']\n",
    "              \n",
    "            for building in allBuildings:   \n",
    "                veri = building['geometry']['coordinates'][0]\n",
    "                \n",
    "                tip = str(building['geometry']['type'])\n",
    "                coordinates = list() \n",
    "                if tip == ('Point'):\n",
    "                    continue\n",
    "                    \n",
    "                elif tip == ('MultiPolygon'):\n",
    "                    \n",
    "                    if isinstance(veri,float): continue\n",
    "                        \n",
    "                    kucukBinalar = (building['geometry']['coordinates'])\n",
    "                    for b in range(len(kucukBinalar)):  \n",
    "                        veri = kucukBinalar[b][0]\n",
    "                        for i in veri:\n",
    "                            xPixel, yPixel = RGBTIFResmi.proj_to_raster(i[0], i[1])\n",
    "                            xPixel = 649 if xPixel > 649 else xPixel\n",
    "                            yPixel = 649 if yPixel > 649 else yPixel\n",
    "                            coordinates.append((xPixel,yPixel)) \n",
    "                else:\n",
    "                    if isinstance(veri,float): continue\n",
    "    \n",
    "                    for i in veri:\n",
    "                        xPixel, yPixel = RGBTIFResmi.proj_to_raster(i[0], i[1])\n",
    "                        xPixel = 649 if xPixel > 649 else xPixel\n",
    "                        yPixel = 649 if yPixel > 649 else yPixel\n",
    "                        coordinates.append((xPixel,yPixel))\n",
    "\n",
    "                maske = fill_between(coordinates)\n",
    "                masks = np.dstack((masks,maske))\n",
    "\n",
    "                \n",
    "        if masks.shape != (650,650):\n",
    "            masks = masks[:,:,1:]\n",
    "            class_ids = np.asarray([1]*masks.shape[2])\n",
    "        else:\n",
    "            class_ids=np.ones((1))\n",
    "            masks = masks.reshape((650,650,1))\n",
    "        return masks.astype(np.bool), class_ids.astype(np.int32)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 10,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "28377edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = SpaceNetDataset()\n",
    "dataset_train.load_dataset(dataset_dir,0,12) \n",
    "dataset_train.prepare()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 11,
   "id": "142e79c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 12\n",
      "Classes: ['BG', 'building']\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11]\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "id": "142e79c4",
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset_train.image_ids), dataset_train.class_names))\n",
    "print(dataset_train.image_ids)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 12,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "f56eae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataset\n",
    "dataset_val = SpaceNetDataset()\n",
    "dataset_val.load_dataset(dataset_dir,12,16)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 13,
   "id": "58940be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 4\n",
      "Classes: ['BG', 'building']\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "id": "58940be9",
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset_val.image_ids), dataset_val.class_names))\n",
    "print(dataset_val.image_ids)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 14,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "e104826d",
   "metadata": {
    "scrolled": false
   },
<<<<<<< Updated upstream
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1660891293.9922967\n",
      "\n",
      "Training network heads\n",
      "\n",
      "\n",
      "Starting at epoch 0. LR=0.3\n",
      "\n",
      "Checkpoint Path: C:\\Users\\carellano.LEGION5PRO-O3OB\\Documents\\IP AppDev\\Final_Project\\SpaceNet\\logs\\spacenet20220819T0841\\mask_rcnn_spacenet_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carellano.LEGION5PRO-O3OB\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(time_start)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining network heads\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mheads\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m time_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     39\u001b[0m time_elapsed_sec \u001b[38;5;241m=\u001b[39m time_end \u001b[38;5;241m-\u001b[39m time_start\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\py39_tf\\lib\\site-packages\\mask_rcnn-2.1-py3.9.egg\\mrcnn\\model.py:2357\u001b[0m, in \u001b[0;36mMaskRCNN.train\u001b[1;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2355\u001b[0m     workers \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mcpu_count()\n\u001b[1;32m-> 2357\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2361\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTEPS_PER_EPOCH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVALIDATION_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2367\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch, epochs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training_v1.py:776\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    775\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[1;32m--> 776\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training_generator_v1.py:570\u001b[0m, in \u001b[0;36mGeneratorOrSequenceTrainingLoop.fit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    567\u001b[0m model\u001b[38;5;241m.\u001b[39m_validate_or_infer_batch_size(batch_size, steps_per_epoch, x)\n\u001b[0;32m    568\u001b[0m training_utils_v1\u001b[38;5;241m.\u001b[39mcheck_generator_arguments(\n\u001b[0;32m    569\u001b[0m     y, sample_weight, validation_split\u001b[38;5;241m=\u001b[39mvalidation_split)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msteps_per_epoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training_generator_v1.py:212\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m step \u001b[38;5;241m<\u001b[39m target_steps:\n\u001b[1;32m--> 212\u001b[0m   batch_data \u001b[38;5;241m=\u001b[39m \u001b[43m_get_next_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m batch_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_dataset:\n\u001b[0;32m    215\u001b[0m       \u001b[38;5;66;03m# The dataset passed by the user ran out of batches.\u001b[39;00m\n\u001b[0;32m    216\u001b[0m       \u001b[38;5;66;03m# Now we know the cardinality of the dataset.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m       \u001b[38;5;66;03m# If steps_per_epoch was specified, then running out of data is\u001b[39;00m\n\u001b[0;32m    218\u001b[0m       \u001b[38;5;66;03m# unexpected, so we stop training and inform the user.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training_generator_v1.py:346\u001b[0m, in \u001b[0;36m_get_next_batch\u001b[1;34m(generator)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 346\u001b[0m   generator_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mStopIteration\u001b[39;00m, tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mOutOfRangeError):\n\u001b[0;32m    348\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\data_utils.py:514\u001b[0m, in \u001b[0;36miter_sequence_infinite\u001b[1;34m(seq)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;124;03m\"\"\"Iterates indefinitely over a Sequence.\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m  Batches of data from the `Sequence`.\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 514\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m seq:\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\data_utils.py:500\u001b[0m, in \u001b[0;36mSequence.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    499\u001b[0m   \u001b[38;5;124;03m\"\"\"Create a generator that iterate over the Sequence.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 500\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mself\u001b[39m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))):\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\data_utils.py:500\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    499\u001b[0m   \u001b[38;5;124;03m\"\"\"Create a generator that iterate over the Sequence.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 500\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))):\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\py39_tf\\lib\\site-packages\\mask_rcnn-2.1-py3.9.egg\\mrcnn\\model.py:1719\u001b[0m, in \u001b[0;36mDataGenerator.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m   1716\u001b[0m \u001b[38;5;66;03m# Get GT bounding boxes and masks for image.\u001b[39;00m\n\u001b[0;32m   1717\u001b[0m image_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_ids[image_index]\n\u001b[0;32m   1718\u001b[0m image, image_meta, gt_class_ids, gt_boxes, gt_masks \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m-> 1719\u001b[0m     \u001b[43mload_image_gt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1720\u001b[0m \u001b[43m                  \u001b[49m\u001b[43maugmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugmentation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;66;03m# Skip images that have no instances. This can happen in cases\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m \u001b[38;5;66;03m# where we train on a subset of classes and the image doesn't\u001b[39;00m\n\u001b[0;32m   1724\u001b[0m \u001b[38;5;66;03m# have any of the classes we care about.\u001b[39;00m\n\u001b[0;32m   1725\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(gt_class_ids \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\py39_tf\\lib\\site-packages\\mask_rcnn-2.1-py3.9.egg\\mrcnn\\model.py:1236\u001b[0m, in \u001b[0;36mload_image_gt\u001b[1;34m(dataset, config, image_id, augmentation)\u001b[0m\n\u001b[0;32m   1234\u001b[0m mask, class_ids \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mload_mask(image_id)\n\u001b[0;32m   1235\u001b[0m original_shape \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m-> 1236\u001b[0m image, window, scale, padding, crop \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMAGE_MIN_DIM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMAGE_MIN_SCALE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMAGE_MAX_DIM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMAGE_RESIZE_MODE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1242\u001b[0m mask \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mresize_mask(mask, scale, padding, crop)\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;66;03m# Augmentation\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;66;03m# This requires the imgaug lib (https://github.com/aleju/imgaug)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\py39_tf\\lib\\site-packages\\mask_rcnn-2.1-py3.9.egg\\mrcnn\\utils.py:447\u001b[0m, in \u001b[0;36mresize_image\u001b[1;34m(image, min_dim, max_dim, min_scale, mode)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# Resize image using bilinear interpolation\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scale \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 447\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mpreserve_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Need padding or cropping?\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquare\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;66;03m# Get new height and width\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\py39_tf\\lib\\site-packages\\mask_rcnn-2.1-py3.9.egg\\mrcnn\\utils.py:899\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;124;03m\"\"\"A wrapper for Scikit-Image resize().\u001b[39;00m\n\u001b[0;32m    890\u001b[0m \n\u001b[0;32m    891\u001b[0m \u001b[38;5;124;03mScikit-Image generates warnings on every call to resize() if it doesn't\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;124;03mversion. And it provides a central place to control resizing defaults.\u001b[39;00m\n\u001b[0;32m    895\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    896\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LooseVersion(skimage\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m LooseVersion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.14\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    897\u001b[0m     \u001b[38;5;66;03m# New in 0.14: anti_aliasing. Default it to False for backward\u001b[39;00m\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# compatibility with skimage 0.13.\u001b[39;00m\n\u001b[1;32m--> 899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mskimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreserve_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manti_aliasing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manti_aliasing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43manti_aliasing_sigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manti_aliasing_sigma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m skimage\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mresize(\n\u001b[0;32m    906\u001b[0m         image, output_shape,\n\u001b[0;32m    907\u001b[0m         order\u001b[38;5;241m=\u001b[39morder, mode\u001b[38;5;241m=\u001b[39mmode, cval\u001b[38;5;241m=\u001b[39mcval, clip\u001b[38;5;241m=\u001b[39mclip,\n\u001b[0;32m    908\u001b[0m         preserve_range\u001b[38;5;241m=\u001b[39mpreserve_range)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\py39_tf\\lib\\site-packages\\skimage\\transform\\_warps.py:187\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m NumpyVersion(scipy\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.6.0\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;66;03m# The grid_mode kwarg was introduced in SciPy 1.6.0\u001b[39;00m\n\u001b[0;32m    186\u001b[0m     zoom_factors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m factors]\n\u001b[1;32m--> 187\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mndi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzoom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom_factors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndi_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# TODO: Remove the fallback code below once SciPy >= 1.6.0 is required.\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# 2-dimensional interpolation\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output_shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(output_shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    194\u001b[0m                                 output_shape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m input_shape[\u001b[38;5;241m2\u001b[39m]):\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\py39_tf\\lib\\site-packages\\scipy\\ndimage\\_interpolation.py:816\u001b[0m, in \u001b[0;36mzoom\u001b[1;34m(input, zoom, output, order, mode, cval, prefilter, grid_mode)\u001b[0m\n\u001b[0;32m    812\u001b[0m zoom \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mdivide(zoom_nominator, zoom_div,\n\u001b[0;32m    813\u001b[0m                     out\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mones_like(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mfloat64),\n\u001b[0;32m    814\u001b[0m                     where\u001b[38;5;241m=\u001b[39mzoom_div \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    815\u001b[0m zoom \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mascontiguousarray(zoom)\n\u001b[1;32m--> 816\u001b[0m \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzoom_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    817\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mgrid_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "\n",
    "\n",
    "#####  MODEL FOR TRAINING  ##############\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(action='ignore', category=DeprecationWarning, message='`np.bool` is a deprecated alias')\n",
    "time_start = time.time()\n",
    "\n",
    "\n",
    "# Create model in training mode  -> SpaceNet config\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)\n",
    "\n",
    "# add weights to model\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "# #checkpoint callbacks\n",
    "# checkpoint_path = \"training_1/cp.ckpt\"\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# # Create a callback that saves the model's weights\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "#                                                  save_weights_only=True,\n",
    "#                                                  verbose=1)\n",
    "\n",
<<<<<<< Updated upstream
    "\n",
=======
>>>>>>> Stashed changes
    "# model.train(dataset_train, dataset_val, \n",
    "#             learning_rate=config.LEARNING_RATE, \n",
    "#             epochs=5, #epoch=200\n",
    "#             layers='all')\n",
    "\n",
    "# Training - Stage 1\n",
    "print(time_start)\n",
    "print(\"\\nTraining network heads\\n\")\n",
    "\n",
    "model.train(dataset_train, dataset_val,\n",
    "        learning_rate=config.LEARNING_RATE*300,\n",
    "        epochs=1,\n",
    "        layers='heads')\n",
    "\n",
    "time_end = time.time()\n",
    "time_elapsed_sec = time_end - time_start\n",
    "\n",
    "print('Total elapsed time: {} seconds'.format(time_elapsed_sec))\n",
    "print('Average latency per batch: {} seconds'.format(time_elapsed_sec / repeat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f5dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0446d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load and display random samples\n",
    "# print(dataset_train.image_ids)\n",
    "# image_ids = np.random.choice(dataset_train.image_ids,2)\n",
    "# print(image_ids)\n",
    "# for image_id in range(len(image_ids)):\n",
    "#     print(image_id)\n",
    "#     image = dataset_train.load_image(image_id)\n",
    "#     mask, class_ids = dataset_train.load_mask(image_id)\n",
    "#     visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d371c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model in inference mode\n",
    "# model = modellib.MaskRCNN(mode=\"inference\", \n",
    "#                           config=inference_config,\n",
    "#                           model_dir=MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2661aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(COCO_MODEL_PATH, by_name=True, exclude=[\n",
    "#             \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "#             \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f5224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_image, image_meta, gt_class_id, gt_bbox, gt_mask =modellib.load_image_gt(dataset_val, inference_config, image_id) #use_mini_mask=False'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a5976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log(\"original_image\", original_image)\n",
    "# log(\"image_meta\", image_meta)\n",
    "# log(\"gt_class_id\", gt_class_id)\n",
    "# log(\"gt_bbox\", gt_bbox)\n",
    "# log(\"gt_mask\", gt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa12896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train(dataset_train, dataset_val, \n",
    "#             learning_rate=config.LEARNING_RATE, \n",
    "# #             epochs=200, \n",
    "#             layers='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88169ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####   DETECTION     ####\n",
    "# class InferenceConfig(SpaceNetConfig):\n",
    "#     GPU_COUNT = 1\n",
    "#     IMAGES_PER_GPU = 1\n",
    "\n",
    "# inference_config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a6f0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae42cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "#                             dataset_train.class_names, figsize=(8, 8))\n",
    "\n",
    "# results = model.detect([original_image], verbose=1)\n",
    "# r = results[0]\n",
    "# visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "#                             dataset_val.class_names, r['scores'], ax=get_ax())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2848d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Compute VOC-Style mAP @ IoU=0.5\n",
    "# # Running on 10 images. Increase for better accuracy.\n",
    "# image_ids = np.random.choice(dataset_val.image_ids, 6)\n",
    "# APs = []\n",
    "# for image_id in image_ids:\n",
    "#     # Load image and ground truth data\n",
    "#     image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "#         modellib.load_image_gt(dataset_val, inference_config,\n",
    "#                                image_id) #, use_mini_mask=False\n",
    "#     molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "#     # Run object detection\n",
    "#     results = model.detect([image], verbose=0)\n",
    "#     r = results[0]\n",
    "#     # Compute AP\n",
    "#     AP, precisions, recalls, overlaps =\\\n",
    "#         utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "#                          r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "#     APs.append(AP)\n",
    "    \n",
    "# print(\"mAP: \", np.mean(APs))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39 (TF2.9.1)",
   "language": "python",
   "name": "py39_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
