{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51735b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import keras\n",
    "# from keras.preprocessing.image import load_img\n",
    "# from keras.preprocessing.image import img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "# Set the ROOT_DIR variable to the root directory of the Mask_RCNN git repo\n",
    "ROOT_DIR = 'C:\\\\Users\\\\carellano.LEGION5PRO-O3OB\\\\Document\\\\GitHub\\\\Mask_RCNN'\n",
    "# assert os.path.exists(ROOT_DIR), 'ROOT_DIR does not exist. Did you forget to read the instructions above? ;)'\n",
    "\n",
    "# Import mrcnn libraries\n",
    "sys.path.append(ROOT_DIR) \n",
    "from mrcnn.config import Config\n",
    "import mrcnn.utils as utils\n",
    "from mrcnn import visualize\n",
    "import mrcnn.model as modellib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa80eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = \"C:\\\\Users\\\\carellano.LEGION5PRO-O3OB\\\\Documents\\\\IP AppDev\\\\Final_Project\\\\SpaceNet_v1\\\\mask_rcnn_spacenet_0151\\\\mask_rcnn_spacenet_0151.h5\"\n",
    "new_model_path = \"C:\\\\Users\\\\carellano.LEGION5PRO-O3OB\\\\Documents\\\\IP AppDev\\\\Final_Project\\\\SpaceNet_v1\\\\transferlearning\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1df8de49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet50\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        350\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  640\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  640\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [640 640   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               250\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           SpaceNet\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.25, 1, 4]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                50\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           5\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               10\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class SpaceNetConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"SpaceNet\"\n",
    "    BACKBONE = \"resnet50\"\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # background + 1 building\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 640\n",
    "    IMAGE_MAX_DIM = 640\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "    RPN_ANCHOR_RATIOS = [0.25, 1, 4]\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 5  #10    #32\n",
    "\n",
    "    USE_MINI_MASK = True\n",
    "    \n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 50 #500\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 10 #50\n",
    "    \n",
    "    MAX_GT_INSTANCES=250\n",
    "    DETECTION_MAX_INSTANCES=350\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "config = SpaceNetConfig()\n",
    "config.display()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fdf1a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method1\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"C:\\\\Users\\\\carellano.LEGION5PRO-O3OB\\\\Documents\\\\IP AppDev\\\\Final_Project\\\\SpaceNet_v1\\\\\")\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)\n",
    "\n",
    "\n",
    "# model = tf.keras.models.load_model(model_path)\n",
    "# tf.saved_model.save(model, new_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2919cdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pretrained model to C:\\Users\\carellano.LEGION5PRO-O3OB\\Documents\\IP AppDev\\Final_Project\\SpaceNet_v1\\mask_rcnn_coco.h5 ...\n",
      "... done downloading pretrained model!\n"
     ]
    }
   ],
   "source": [
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "295b87ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected an object of type `Trackable`, such as `tf.Module` or a subclass of the `Trackable` class, for export. Got <mrcnn.model.MaskRCNN object at 0x00000222ADBA5280> with type <class 'mrcnn.model.MaskRCNN'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(COCO_MODEL_PATH, by_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exclude\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmrcnn_class_logits\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmrcnn_bbox_fc\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmrcnn_bbox\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmrcnn_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# model.save(\"new_model_path\")\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_model_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\saved_model\\save.py:1290\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[0;32m   1289\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWriteApi(_SAVE_V2_LABEL)\n\u001b[1;32m-> 1290\u001b[0m \u001b[43msave_and_return_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1291\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWrite(write_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\saved_model\\save.py:1325\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[1;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[0;32m   1321\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m saved_model_pb2\u001b[38;5;241m.\u001b[39mSavedModel()\n\u001b[0;32m   1322\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m saved_model\u001b[38;5;241m.\u001b[39mmeta_graphs\u001b[38;5;241m.\u001b[39madd()\n\u001b[0;32m   1324\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1325\u001b[0m     \u001b[43m_build_meta_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1326\u001b[0m saved_model\u001b[38;5;241m.\u001b[39msaved_model_schema_version \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1327\u001b[0m     constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;66;03m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;66;03m# the SavedModel proto itself.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\saved_model\\save.py:1491\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[1;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[0;32m   1466\u001b[0m \u001b[38;5;124;03m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[0;32m   1467\u001b[0m \n\u001b[0;32m   1468\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;124;03m  asset_info: `_AssetInfo` tuple containing external assets in the `obj`.\u001b[39;00m\n\u001b[0;32m   1488\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1490\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save_context\u001b[38;5;241m.\u001b[39msave_context(options):\n\u001b[1;32m-> 1491\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_meta_graph_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\saved_model\\save.py:1425\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[1;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, base\u001b[38;5;241m.\u001b[39mTrackable):\n\u001b[1;32m-> 1425\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1426\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected an object of type `Trackable`, such as `tf.Module` or a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1427\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubclass of the `Trackable` class, for export. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1428\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1429\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m meta_graph_def \u001b[38;5;129;01mor\u001b[39;00m meta_graph_pb2\u001b[38;5;241m.\u001b[39mMetaGraphDef()\n\u001b[0;32m   1431\u001b[0m augmented_graph_view \u001b[38;5;241m=\u001b[39m _AugmentedGraphView(obj)\n",
      "\u001b[1;31mValueError\u001b[0m: Expected an object of type `Trackable`, such as `tf.Module` or a subclass of the `Trackable` class, for export. Got <mrcnn.model.MaskRCNN object at 0x00000222ADBA5280> with type <class 'mrcnn.model.MaskRCNN'>."
     ]
    }
   ],
   "source": [
    "# load weights (mscoco) and exclude the output layers\n",
    "\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "# model.save(\"new_model_path\")\n",
    "tf.saved_model.save(model, new_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944ef9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method 2\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "# model.save(\"new_model_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b964fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "h5py.run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ddb340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method3\n",
    "\n",
    "method = input(\"Input the type of model loading (JSON or H5):\")\n",
    "if method == 'JSON':    \n",
    "    #load acritecture from json file\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json, custom_objects={'BatchNorm':BatchNorm, 'tf':tf, 'ProposalLayer':ProposalLayer, 'PyramidROIAlign1':PyramidROIAlign1, 'PyramidROIAlign2':PyramidROIAlign2, 'DetectionLayer':DetectionLayer})\n",
    "\n",
    "    # load weights into new model\n",
    "    model.load_weights(\"trained_weights.h5\", by_name=True)\n",
    "    print(\"Loaded model from disk\")\n",
    "\n",
    "elif method == 'H5':\n",
    "    #load entire model\n",
    "    model = keras.models.load_model('model.h5', custom_objects={'BatchNorm':BatchNorm, 'tf':tf, 'ProposalLayer':ProposalLayer, 'PyramidROIAlign1':PyramidROIAlign1, 'PyramidROIAlign2':PyramidROIAlign2, 'DetectionLayer':DetectionLayer}, compile=False)\n",
    "    print(\"Loaded model from disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39 (TF2.9.1)",
   "language": "python",
   "name": "py39_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
